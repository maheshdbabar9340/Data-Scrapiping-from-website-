{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    " \n",
    "rank_page = 'https://socialblade.com/youtube/top/50/mostviewed'\n",
    "req = urllib3.PoolManager()\n",
    "request = req.request('GET', rank_page)\n",
    "# page = urllib3.urlopen(request)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "r = requests.get('https://socialblade.com/youtube/top/50/mostviewed')\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    " \n",
    "channels = soup.find('div', attrs={'style': 'float: right; width: 900px;'})\n",
    " \n",
    "file = open('topyoutubers.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    " \n",
    "# write title row\n",
    "writer.writerow(['Username', 'Uploads', 'Views'])\n",
    " \n",
    "print(channels)\n",
    "# for channel in channels:\n",
    "#     username = channel.find('div', attrs={'style': 'float: left; width: 350px; line-height: 25px;'}).a.text.strip()\n",
    "#     uploads = channel.find('div', attrs={'style': 'float: left; width: 80px;'}).span.text.strip()\n",
    "#     views = channel.find_all('div', attrs={'style': 'float: left; width: 150px;'})[1].span.text.strip()\n",
    " \n",
    "#     print(username + ' ' + uploads + ' ' + views)\n",
    "#     writer.writerow([username.encode('utf-8'), uploads.encode('utf-8'), views.encode('utf-8')])\n",
    " \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement urllib2 (from versions: )\n",
      "No matching distribution found for urllib2\n"
     ]
    }
   ],
   "source": [
    "pip install urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Username' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7e212c244230>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# write title row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUsername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUploads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mViews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# for channel in channels:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Username' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    " \n",
    "# rank_page = 'https://socialblade.com/youtube/top/50/mostviewed'\n",
    "# request = urllib.request(rank_page)\n",
    "# page = urllib.urlopen(request)\n",
    "# soup = BeautifulSoup(page, 'html.parser')\n",
    " \n",
    "# channels = soup.find('div', attrs={'style': 'float: right; width: 900px;'}).find_all('div', recursive=False)[4:]\n",
    " \n",
    "file = open('topyoutubers.csv', 'wb')\n",
    "writer = csv.writer(file)\n",
    " \n",
    "# write title row\n",
    "writer.writerow([Username, Uploads, Views])\n",
    " \n",
    "# for channel in channels:\n",
    "#     username = channel.find('div', attrs={'style': 'float: left; width: 350px; line-height: 25px;'}).a.text.strip()\n",
    "#     uploads = channel.find('div', attrs={'style': 'float: left; width: 80px;'}).span.text.strip()\n",
    "#     views = channel.find_all('div', attrs={'style': 'float: left; width: 150px;'})[1].span.text.strip()\n",
    " \n",
    "#     print(username + ' ' + uploads + ' ' + views)\n",
    "#     writer.writerow([username.encode('utf-8'), uploads.encode('utf-8'), views.encode('utf-8')])\n",
    " \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('c:\\\\Users\\\\mahes\\\\Desktop\\\\Welocme.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "worksheet.write('A1', 'Name of the student')\n",
    "worksheet.write('B1', 'Subject')\n",
    "\n",
    "row = 1\n",
    "col = 0\n",
    " \n",
    "data = ( \n",
    "    ['Rajendra', 'IT'], \n",
    "    ['Kashish','Physiotherapist'], \n",
    "    ['Arun', 'Student'], \n",
    "    ['Rohan','Bank Manager'], \n",
    ") \n",
    " \n",
    "for name, score in (data): \n",
    "    worksheet.write(row, col, name) \n",
    "    worksheet.write(row, col + 1, score) \n",
    "    row += 1\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Atta Dal Rice Combo - Chakki Atta 5 kg + Toor Dal 2 kg + Surti Kolam Rice 2 kg', ' 21% OFF '],), (['Aashirvaad Whole Wheat Atta 1 kg', ' 7% OFF '],), (['Broken Wheat / Daliya 500 g', ' 50% OFF '],), (['Broken Wheat / Daliya 1 kg', ' 50% OFF '],), (['Good Life MP Wheat Chakki Atta 1 kg', ' 22% OFF '],), (['Fortune Chakki Fresh Whole Wheat Atta 10 kg', ' 14% OFF '],), (['Nature Fresh Sampoorna Chakki Whole Wheat Atta 10 kg', ' 23% OFF '],), (['Uttam Rawa / Sooji 1 kg', ' 18% OFF '],), (['Madam Rawa 500 g', ' 7% OFF '],), ([\"Uttam Wheat's Daliya 500 g\", ' 12% OFF '],), (['Besan 1 kg', ' 53% OFF '],), (['Besan 500 g', ' 53% OFF '],), (['Madam Rice Atta / Flour 500 g', ' 7% OFF '],), (['Gaay Chhap Maraiyo / Varai 500 g', ' 7% OFF '],), (['Rawa 500 g', ' 53% OFF '],), (['Manna Diabetic Multigrain Atta 1 kg', ' 10% OFF '],), (['Manna Plain Ragi Flour 500 g', ' 10% OFF '],), (['Manna Rice Flour 500 g', ' 10% OFF '],), (['Manna Rice Flour 1 kg', ' 10% OFF '],), (['Aashirvaad Whole Wheat Atta 10 kg', ' 15% OFF '],)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# filename = 'atta.csv'\n",
    "# f=open(filename, 'w', newline ='')\n",
    "# atta = csv.writer(f)\n",
    "\n",
    "url = ('https://www.jiomart.com/c/groceries/staples/atta-flours-sooji/26')\n",
    "\n",
    "def scraping_images(url, folder):\n",
    "    try: \n",
    "        os.mkdir(os.path.join(os.getcwd(), folder))\n",
    "    except: \n",
    "        pass\n",
    "    os.chdir(os.path.join(os.getcwd(), folder))\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    images = soup.find_all('img')\n",
    "    image_link = []\n",
    "    \n",
    "    for image in images:\n",
    "        link = image['src']\n",
    "        image_link.append(link)\n",
    "    return image_link  \n",
    "    \n",
    "\n",
    "def imagedown(url, folder):\n",
    "    try: \n",
    "        os.mkdir(os.path.join(os.getcwd(), folder))\n",
    "    except: \n",
    "        pass\n",
    "    os.chdir(os.path.join(os.getcwd(), folder))\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    products = soup.find_all('div', class_=\"row product-list\")\n",
    "    \n",
    "    for product in products:\n",
    "        product_name = product.find_all('span', class_='clsgetname')\n",
    "        product_discount = product.find_all('span', class_='dis_section')\n",
    "        \n",
    "        x = list(zip(product_name,product_discount))\n",
    "\n",
    "        outer_list = []  \n",
    "        for y in x:\n",
    "            inner_list = []\n",
    "            for z in y:\n",
    "                inner_list.append(z.text)\n",
    "            outer_list.append(inner_list)\n",
    "        \n",
    "            \n",
    "        main_list = list(zip(outer_list))\n",
    "        print(main_list)\n",
    "#         for i in main_list:\n",
    "#             print(i)\n",
    "\n",
    "        \n",
    "imagedown('https://www.jiomart.com/c/groceries/staples/atta-flours-sooji/26', 'Atta Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urllib2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-846c1dbd158b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0murllib2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'urllib2'"
     ]
    }
   ],
   "source": [
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement urllib2 (from versions: )\n",
      "No matching distribution found for urllib2\n"
     ]
    }
   ],
   "source": [
    "pip install urllib2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d63e65231685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.agrayellowpages.in/agricultural-cf-agents.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-d63e65231685>\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#         print(i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m't_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import xlsxwriter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "\n",
    "\n",
    "# import xlsxwriter\n",
    "# workbook = xlsxwriter.Workbook('c:\\\\Users\\\\mahes\\\\Desktop\\\\Welocme.xlsx')\n",
    "# worksheet = workbook.add_worksheet()\n",
    "# worksheet.write('A1', 'Name of the student')\n",
    "# worksheet.write('B1', 'Mobile Number')\n",
    "\n",
    "# row = 1\n",
    "# col = 0\n",
    " \n",
    "# data = ( \n",
    "#     ['Rajendra', 'IT'], \n",
    "#     ['Kashish','Physiotherapist'], \n",
    "#     ['Arun', 'Student'], \n",
    "#     ['Rohan','Bank Manager'], \n",
    "# ) \n",
    " \n",
    "data = ()\n",
    "\n",
    "\n",
    "# for name, score in (data): \n",
    "#     worksheet.write(row, col, name) \n",
    "#     worksheet.write(row, col + 1, score) \n",
    "#     row += 1\n",
    "# workbook.close()\n",
    "\n",
    "\n",
    "def getData(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    images = soup.find_all('h2')\n",
    "    first = []\n",
    "    second = []\n",
    "    for i in images:\n",
    "#         print(i)\n",
    "        first = first.append(i.text)\n",
    "    \n",
    "    image = soup.find_all('span', class_='t_2')\n",
    "    \n",
    "    for j in image:\n",
    "#         print(i)\n",
    "        second = second.append(i.text)\n",
    "    \n",
    "    print(first, second)\n",
    "    \n",
    "getData('http://www.agrayellowpages.in/agricultural-cf-agents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Gopal Trading Co\n",
      "Deals in Agriculture Hardware, Spare Parts, Tools, Agriculture Machinery, Agriculture Equipments.Street Address :21/62, FreeGanj, Agra-282001, Uttar Pradesh, IndiaPhone :+91-562-2267059City :Agra\n",
      "Website : http://www.agrayellowpages.in/Gopal-Trading-Co.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Chaudhary Agro Field\n",
      "Deals in Agriculture Machinery, Agriculture Equipments & spare partsStreet Address :Rohta Ka Bagh, Gwalior Road, Agra-282001, Uttar Pradesh, IndiaCity :Agra\n",
      "Website : http://www.agrayellowpages.in/Chaudhary-Agro-Field.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Nand Kishor Lalaram & Co\n",
      "Deals in Agriculture Equipments, Machines & spare partsStreet Address :4/63, Opposite DIG Kothi, BaluGanj, Agra-282001, Uttar Pradesh, IndiaPhone :+91-562-2363021City :Agra\n",
      "Website : http://www.agrayellowpages.in/Nand-Kishor-Lalaram-and-Co.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Shyamji Pumps\n",
      "Deals in Agriculture PumpsStreet Address :Tara Niwas Belangaj, Agra-282001, Uttar Pradesh, IndiaMobile :+91-9359354181City :Agra\n",
      "Website : http://www.agrayellowpages.in/Shyamji-Pumps.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Shree bhagwan seeds\n",
      "We provide all kinds of vegetables seeds, fruits plan seeds, Agricultural Equipments & MachineryStreet Address :Rohta, Near Punjab National Bank, Gwalior Road, Agra - 282001, Uttar Pradesh, IndiaMobile :+91-9411001127City :Agra\n",
      "Website : http://www.agrayellowpages.in/Shree-bhagwan-seeds.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Guruji Agriculture\n",
      "We offer Agricultural Equipments & MachineryStreet Address :opposite prathmik swastiya bkendra, Agra road, Shamsabad, Agra - 282001, Uttar Pradesh, IndiaMobile :+91-9758826506City :Agra\n",
      "Website : http://www.agrayellowpages.in/Guruji-Agriculture.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Jaiswal Agriculture A DV Centre\n",
      "Agricultural Equipments & MachineryStreet Address :Chhipitola, Agra - 282001, Uttar Pradesh, IndiaMobile :+91-9568342554City :Agra\n",
      "Website : http://www.agrayellowpages.in/Jaiswal -Agriculture-ADV-Centre.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Kishan Agriculture\n",
      "Deals in Agriculture Bend, Pulley, Equipments, Toos, and Agriculture Value Machines.Street Address :Mahveer Nagar, Chhipitola, Agra - 282001, Uttar Pradesh, IndiaMobile :+91-562-2366991City :Agra\n",
      "Website : http://www.agrayellowpages.in/Kishan-Agriculture.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Lala Ram Mahesh Kumar Jain\n",
      "We offer Agricultural Equipments & Machinery and other related products.Street Address :29/231, Chhipitola Agra, Chhipitola, Agra - 282001, Uttar Pradesh, IndiaMobile :+91-9368603533City :Agra\n",
      "Website : http://www.agrayellowpages.in/Lala-Ram-Mahesh-Kumar-Jain.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Nand Kishore Lala Ram Jain And Company\n",
      "Deals in Tractor, Agricultural Equipment & \r\n",
      "Cultivator.Street Address :4/63, BaluGanj, Agra-282001, Uttar Pradesh, IndiaMobile :+91-9368603533City :Agra\n",
      "Website : http://www.agrayellowpages.in/Nand Kishore Lala Ram Jain And Company.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Vardhman Hardware Store\n",
      "Deals in Hardware, Agricultural Equipment, Lubricant Oil, Hardware Tools & Agriculture AccessoriesStreet Address :Fatehabad Road, Dhemshri, Tehsil-Fatehabad, District-Agra, Fatehabad Road, Agra - 282001Mobile :+91-9897625466City :Agra\n",
      "Website : http://www.agrayellowpages.in/Vardhman-Hardware-Store.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Chaudhary B S Krishi Yantra Udyog\n",
      "Deals in agricultural implements & equipments.Street Address :Choudhary Agrofield, Rohta Ka Bagh, Gwalior Road,  Near Punjab National Bank, Agra, Uttar PradeshContact Person :Mr MukeshPhone :+91-562-2961416Mobile :+91-9410004320, 9359736882City :Agra\n",
      "Website : http://www.agrayellowpages.in/chaudhary-b-s-krishi-yantra-udyog.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "S. L. Agarwal Fertilizer & Chemicals\n",
      "Deals in Fertilizer & ChemicalsStreet Address :98, New Market, Jeoni Mandi, Agra, Uttar Pradesh, (INDIA)Contact Person :Mr. Mukesh AgarwalPhone :+91-562-2621866, 2623576Mobile :+91-9412258452City :Agra\n",
      "Website : http://www.agrayellowpages.in/sl-agarwal-fertilizer-&-chemicals.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "Aruti Agritech India Pvt Ltd\n",
      "Deals in agriculture.Street Address :A-3, Indur Puri, New Agra, Agra, Uttar PradeshContact Person :Mr. Kishor KumarPhone :+91-562-4004697, 2623570Mobile :+91-9319818732City :Agra\n",
      "Website : http://www.agrayellowpages.in/aruti-agritech-india-pvt-ltd-8.htm\n",
      "View Details\n",
      "Send Inquiry\n",
      "\n",
      "+91-9359354181\n",
      "+91-9411001127\n",
      "+91-9758826506\n",
      "+91-9568342554\n",
      "+91-562-236699\n",
      "+91-9368603533\n",
      "+91-9368603533\n",
      "+91-9897625466\n",
      "+91-9410004320\n",
      "+91-9412258452\n",
      "+91-9319818732\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import xlsxwriter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "\n",
    "\n",
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('c:\\\\Users\\\\mahes\\\\Desktop\\\\Welocme.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "worksheet.write('A1', 'Name of the student')\n",
    "worksheet.write('B1', 'Mobile Number')\n",
    "\n",
    "row = 1\n",
    "col = 0\n",
    " \n",
    "data = ( \n",
    "    ['Rajendra', 'IT'], \n",
    "    ['Kashish','Physiotherapist'], \n",
    "    ['Arun', 'Student'], \n",
    "    ['Rohan','Bank Manager'], \n",
    ") \n",
    " \n",
    "data = ()\n",
    "\n",
    "\n",
    "# for name, score in (data): \n",
    "#     worksheet.write(row, col, name) \n",
    "#     worksheet.write(row, col + 1, score) \n",
    "#     row += 1\n",
    "# workbook.close()\n",
    "\n",
    "\n",
    "def getData(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    first = soup.find_all('td')\n",
    "\n",
    "    dat = []\n",
    "    for i in first:\n",
    "        dat.append(i.text)\n",
    "#         print(i.text.strip())\n",
    "#     print(dat)\n",
    "    \n",
    "    for i in dat:\n",
    "        print(i.strip())\n",
    "#             j.strip()\n",
    "#             if(j.find('Mobile') == 0):\n",
    "#                print(j + \"mahiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    second = soup.find_all('div', class_='t_1')\n",
    "\n",
    "    data = []\n",
    "    secfinal = []\n",
    "    for i in second:\n",
    "        data.append(i.text.strip())\n",
    "#         print(i.text.strip())\n",
    "#     print(data)\n",
    "    \n",
    "    for i in data:\n",
    "        if(i.find('Mobile') == 0):\n",
    "            print(i[8:22])\n",
    "#            secfinal.append(i[8:22])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "getData('http://www.agrayellowpages.in/agricultural-cf-agents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '9', '1', '-', '9', '3', '5', '9', '3', '5', '4', '1', '8', '1', '+', '9', '1', '-', '9', '4', '1', '1', '0', '0', '1', '1', '2', '7', '+', '9', '1', '-', '9', '7', '5', '8', '8', '2', '6', '5', '0', '6', '+', '9', '1', '-', '9', '5', '6', '8', '3', '4', '2', '5', '5', '4', '+', '9', '1', '-', '5', '6', '2', '-', '2', '3', '6', '6', '9', '9', '+', '9', '1', '-', '9', '3', '6', '8', '6', '0', '3', '5', '3', '3', '+', '9', '1', '-', '9', '3', '6', '8', '6', '0', '3', '5', '3', '3', '+', '9', '1', '-', '9', '8', '9', '7', '6', '2', '5', '4', '6', '6', '+', '9', '1', '-', '9', '4', '1', '0', '0', '0', '4', '3', '2', '0', '+', '9', '1', '-', '9', '4', '1', '2', '2', '5', '8', '4', '5', '2', '+', '9', '1', '-', '9', '3', '1', '9', '8', '1', '8', '7', '3', '2']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import xlsxwriter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "\n",
    "def getData(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    second = soup.find_all('div', class_='t_1')\n",
    "\n",
    "    data = []\n",
    "    secfinal = []\n",
    "    for i in second:\n",
    "        data.append(i.text.strip())\n",
    "#         print(i.text.strip())\n",
    "#     print(data)\n",
    "    \n",
    "    workbook = xlsxwriter.Workbook(\"C:\\\\Users\\\\mahes\\\\Desktop\\\\try.xlsx\")\n",
    "    worksheet1 = workbook.add_worksheet()\n",
    "    \n",
    "    for i in data:\n",
    "        if((i.find('Mobile') == 0) and (i[8:12] == \"+91-\")):\n",
    "#             print(i[8:22])\n",
    "            secfinal.append(i[8:22])\n",
    "    \n",
    "    from itertools import chain\n",
    "\n",
    "    list1 = list(chain(*secfinal))\n",
    "    \n",
    "    print(list1)\n",
    "\n",
    "    for row_num, data in enumerate(secfinal):\n",
    "        worksheet1.write(row_num, 0, data)\n",
    "        \n",
    "    workbook.close()\n",
    "        \n",
    "    return(secfinal)\n",
    "        \n",
    "        \n",
    "def getMobile(url):\n",
    "    \n",
    "    if(url == 'http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=agricultural-inputs-fertilizers&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)      \n",
    "    \n",
    "    else:\n",
    "        getData(url)\n",
    "        \n",
    "getMobile('http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+91-9928011115', '+91-9828552618', '+91-9486446909', '+91-9412280839', '+91-9922951162', '+91-9756718463', '+91-9756200515', '+91-9610045555', '+91-9001610666', '+91-9001610666', '+91-9970848060', '+91-9557931339', '+91-7669701410'], ['+91-9319737362', '+91-9720105338', '+91-9837055498', '+91-9557470810', '+91-9411463987']]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import xlsxwriter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "\n",
    "def getData(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    second = soup.find_all('div', class_='t_1')\n",
    "\n",
    "    data = []\n",
    "    secfinal = []\n",
    "    for i in second:\n",
    "        data.append(i.text.strip())\n",
    "#         print(i.text.strip())\n",
    "#     print(data)\n",
    "    \n",
    "    for i in data:\n",
    "        if((i.find('Mobile') == 0) and (i[8:12] == \"+91-\")):\n",
    "#             print(i[8:22])\n",
    "           secfinal.append(i[8:22])\n",
    "    return(secfinal)\n",
    "        \n",
    "        \n",
    "def getMobile(url):\n",
    "    \n",
    "    if(url == 'http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=agricultural-inputs-fertilizers&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/food-products.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/food-products.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=food-products&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/agricultural-equipment-implements.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/agricultural-equipment-implements.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=agricultural-equipment-implements&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/agricultural-pipes.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/agricultural-pipes.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=agricultural-pipes&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/dairy-products.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/dairy-products.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=dairy-products&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "#  Agriculture\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/bangles-shop-mfrs-distributor.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/bangles-shop-mfrs-distributor.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=bangles-shop-mfrs-distributor&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/exporters-leather-goods-shoes.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/exporters-leather-goods-shoes.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=exporters-leather-goods-shoes&page=2'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=exporters-leather-goods-shoes&page=3'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/boutiques.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/boutiques.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=boutiques&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/leather-goods-accessories.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/leather-goods-accessories.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=leather-goods-accessories&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "#  Apperals and garments\n",
    "\n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-accessories.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-accessories.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-accessories&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobile-car-gas-converters-cng-lpg.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobile-car-gas-converters-cng-lpg.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobile-car-gas-converters-cng-lpg&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-manufactures-dealers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-manufactures-dealers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-manufactures-dealers&page=2'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-manufactures-dealers&page=3'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-garages-service-centre.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-garages-service-centre.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-garages-service-centre&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-gas-kit.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-gas-kit.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-gas-kit&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-used-cars.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-used-cars.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-used-cars&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/ball-roller-bearing-bushes.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/ball-roller-bearing-bushes.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=ball-roller-bearing-bushes&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/battery-storage.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/battery-storage.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=battery-storage&page=2'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=battery-storage&page=3'))\n",
    "\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/automobiles-manufactures-dealers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/automobiles-manufactures-dealers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-manufactures-dealers&page=2'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=automobiles-manufactures-dealers&page=3'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/diesel-engines-manfacturer-dealers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/diesel-engines-manfacturer-dealers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=diesel-engines-manfacturer-dealers&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/diesel-engines-spares-manufacturers-dealers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/diesel-engines-spares-manufacturers-dealers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=diesel-engines-spares-manufacturers-dealers&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "#   Automobiles\n",
    "\n",
    "    elif(url == 'http://www.agrayellowpages.in/ayurvedic-medicines.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/ayurvedic-medicines.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=ayurvedic-medicines&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/beauty-saloons-beauticians.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/beauty-saloons-beauticians.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=beauty-saloons-beauticians&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "#   Aurvedic and Herbal\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/bicycle-manufacturers-dealers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/bicycle-manufacturers-dealers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=bicycle-manufacturers-dealers&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "#   Bicyles & Rickshaw\n",
    "\n",
    "    elif(url == 'http://www.agrayellowpages.in/business-services.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/business-services.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=business-services&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/interior-decorators-designers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/interior-decorators-designers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=interior-decorators-designers&page=2'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=interior-decorators-designers&page=3'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/share-brokers-consultants-otc-exchanges.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/share-brokers-consultants-otc-exchanges.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=share-brokers-consultants-otc-exchanges&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/tax-practitioners-agents-consultants.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/tax-practitioners-agents-consultants.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "            \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)\n",
    "    \n",
    " \n",
    "    else:\n",
    "        getData(url)\n",
    "        \n",
    "getMobile('http://www.agrayellowpages.in/food-products.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import xlsxwriter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "\n",
    "def getData(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    second = soup.find_all('div', class_='t_1')\n",
    "\n",
    "    data = []\n",
    "    secfinal = []\n",
    "    for i in second:\n",
    "        data.append(i.text.strip())\n",
    "    \n",
    "    for i in data:\n",
    "        if((i.find('Mobile') == 0) and (i[8:12] == \"+91-\")):\n",
    "#             print(i[8:22])\n",
    "            secfinal.append(i[8:22])\n",
    "   \n",
    "    return(secfinal)\n",
    "\n",
    "\n",
    "        \n",
    "def getMobile(url):\n",
    "    workbook = xlsxwriter.Workbook(\"C:\\\\Users\\\\mahes\\\\Desktop\\\\try.xlsx\")\n",
    "    worksheet1 = workbook.add_worksheet()\n",
    "    \n",
    "    if(url == 'http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/agricultural-inputs-fertilizers.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=agricultural-inputs-fertilizers&page=2'))\n",
    "        from functools import reduce\n",
    "        single_list = reduce(lambda x,y: x+y, x)\n",
    "        print(single_list)\n",
    "        for row_num, data in enumerate(single_list):\n",
    "            worksheet1.write(row_num, 0, data)\n",
    "            \n",
    "        \n",
    "    elif(url == 'http://www.agrayellowpages.in/biotechnology.html'):\n",
    "        x = []\n",
    "        x.append(getData('http://www.agrayellowpages.in/biotechnology.html'))\n",
    "        x.append(getData('http://www.agrayellowpages.in/listing/?id=biotechnology&page=2'))\n",
    "        print(x)      \n",
    "    \n",
    "    else:\n",
    "        x = []\n",
    "        x.append(getData(url))\n",
    "        from functools import reduce\n",
    "        single_list = reduce(lambda x,y: x+y, x)\n",
    "        \n",
    "        for row_num, data in enumerate(single_list):\n",
    "            worksheet1.write(row_num, 0, data)\n",
    "        \n",
    "    workbook.close()\n",
    "getMobile('http://www.agrayellowpages.in/agricultural-cf-agents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flatten\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement flatten (from versions: )\n",
      "No matching distribution found for flatten\n"
     ]
    }
   ],
   "source": [
    "pip install flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
